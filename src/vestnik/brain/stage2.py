from __future__ import annotations
import os

import hashlib
import json
from datetime import datetime
from typing import Optional

from vestnik.settings import (
    OPENAI_API_KEY,
    OPENAI_BASE_URL,
    AI_MAX_RETRIES,
    AI_RETRY_SLEEP_SEC,
)
from vestnik.brain.openai_http import OpenAIConfig, chat_text
from vestnik.brain.stage1 import Stage1Item


def _clip_4096(s: str) -> str:
    s = (s or "").strip()
    if len(s) <= 4096:
        return s
    return s[:4090].rstrip() + "â€¦"


def _input_hash(pack_key: str, start: datetime, end: datetime, prompt: str, model: str, items: list[Stage1Item]) -> str:
    payload = {
        "pack_key": pack_key,
        "start": start.isoformat(),
        "end": end.isoformat(),
        "prompt": prompt,
        "model": model,
        "items": [
            {
                "channel_ref": i.channel_ref,
                "message_id": i.message_id,
                "text_sha256": i.text_sha256,
                "summary": i.summary,
                "url": i.url,
                "channel_name": i.channel_name,
            }
            for i in items
        ],
    }
    raw = json.dumps(payload, ensure_ascii=False, sort_keys=True)
    return hashlib.sha256(raw.encode("utf-8")).hexdigest()


async def run_stage2(
    *,
    model: str,
    pack_key: str,
    pack_name: str,
    start: datetime,
    end: datetime,
    prompt_text: str,
    items: list[Stage1Item],
) -> tuple[str, str]:
    if not (os.getenv("DEEPSEEK_API_KEY","") or os.getenv("OPENAI_API_KEY","")):
        raise RuntimeError("AI API key is empty (set DEEPSEEK_API_KEY or OPENAI_API_KEY)")
cfg = OpenAIConfig(
        api_key=OPENAI_API_KEY,
        base_url=OPENAI_BASE_URL,
        max_retries=int(AI_MAX_RETRIES),
        retry_sleep_sec=int(AI_RETRY_SLEEP_SEC),
    )

    # Keep input compact: stage2 consumes only processed facts, not raw posts.
    facts = [
        {
            "title": i.summary.split(".")[0][:140],
            "summary": i.summary,
            "url": i.url,
            "channel": i.channel_name,
        }
        for i in items
    ]

    system = (
        "Ğ¢Ñ‹ â€” Stage 2 ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Â«Ğ§Ğ¸ÑÑ‚Ñ‹Ğ¹ Ğ²ĞµÑÑ‚Ğ½Ğ¸ĞºÂ».\n"
        "Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: ÑÑ‚ĞµÑ€Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹, Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹, Ğ±ĞµĞ· Ğ¾Ñ†ĞµĞ½Ğ¾Ğº.\n"
        "Ğ—Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½Ğ¾ Ğ´Ğ¾Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ°ĞºÑ‚Ñ‹.\n"
        "Ğ’Ñ‹Ñ…Ğ¾Ğ´: Ğ¾Ğ´Ğ¸Ğ½ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾ 4096 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ².\n"
        "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ¸Ğ· Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
    )

    user = (
        f"PACK_NAME: {pack_name}\n"
        f"PACK_KEY: {pack_key}\n"
        f"PERIOD: {start.strftime('%Y-%m-%d %H:%M')} â€” {end.strftime('%Y-%m-%d %H:%M')}\n\n"
        f"PROMPT_RULES:\n{prompt_text.strip()}\n\n"
        f"STAGE1_FACTS_JSON:\n{json.dumps(facts, ensure_ascii=False)}\n\n"
        "Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ:\n"
        "ğŸ“… Ğ§Ğ˜Ğ¡Ğ¢ĞĞ¯ Ğ¡Ğ’ĞĞ”ĞšĞ: {PACK_NAME}\n"
        "ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {START} â€” {END}\n"
        "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²: {COUNT}\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ğŸ”¥ Ğ¤ĞĞšĞ¢Ğ« Ğ˜ Ğ¡ĞĞ‘Ğ«Ğ¢Ğ˜Ğ¯\n"
        "â€¢ ...\n"
        "ğŸ”— ...\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ğŸ“ˆ Ğ¢Ğ Ğ•ĞĞ”Ğ«\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "âš¡ï¸ Ğ¡Ğ˜Ğ“ĞĞĞ›Ğ«\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ğŸ“Š Ğ¡Ğ˜ĞĞ¢Ğ•Ğ—\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        "ğŸ· #Ğ§Ğ¸ÑÑ‚Ñ‹Ğ¹Ğ’ĞµÑÑ‚Ğ½Ğ¸Ğº #"
        + pack_key
        + "\n"
        "ĞĞµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ²Ğ½Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ğ°."
    )

    txt = await chat_text(
        cfg,
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=0.2,
        max_tokens=1400,
    )

    ih = _input_hash(pack_key, start, end, prompt_text, model, items)
    return _clip_4096(txt), ih
